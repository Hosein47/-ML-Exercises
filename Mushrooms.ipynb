{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      "class                       8124 non-null object\n",
      "cap-shape                   8124 non-null object\n",
      "cap-surface                 8124 non-null object\n",
      "cap-color                   8124 non-null object\n",
      "bruises                     8124 non-null object\n",
      "odor                        8124 non-null object\n",
      "gill-attachment             8124 non-null object\n",
      "gill-spacing                8124 non-null object\n",
      "gill-size                   8124 non-null object\n",
      "gill-color                  8124 non-null object\n",
      "stalk-shape                 8124 non-null object\n",
      "stalk-root                  8124 non-null object\n",
      "stalk-surface-above-ring    8124 non-null object\n",
      "stalk-surface-below-ring    8124 non-null object\n",
      "stalk-color-above-ring      8124 non-null object\n",
      "stalk-color-below-ring      8124 non-null object\n",
      "veil-type                   8124 non-null object\n",
      "veil-color                  8124 non-null object\n",
      "ring-number                 8124 non-null object\n",
      "ring-type                   8124 non-null object\n",
      "spore-print-color           8124 non-null object\n",
      "population                  8124 non-null object\n",
      "habitat                     8124 non-null object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:91: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=24, units=12, kernel_initializer=\"uniform\")`\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"uniform\")`\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:95: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=10, kernel_initializer=\"uniform\")`\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "/Users/Psychology/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "6499/6499 [==============================] - 2s 282us/step - loss: 0.2664 - acc: 0.8992\n",
      "Epoch 2/8\n",
      "6499/6499 [==============================] - 2s 247us/step - loss: 0.0539 - acc: 0.9765\n",
      "Epoch 3/8\n",
      "6499/6499 [==============================] - 1s 209us/step - loss: 0.0348 - acc: 0.9818\n",
      "Epoch 4/8\n",
      "6499/6499 [==============================] - 1s 189us/step - loss: 0.0192 - acc: 0.9897\n",
      "Epoch 5/8\n",
      "6499/6499 [==============================] - 1s 202us/step - loss: 0.0050 - acc: 0.9994\n",
      "Epoch 6/8\n",
      "6499/6499 [==============================] - 1s 208us/step - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 7/8\n",
      "6499/6499 [==============================] - 1s 205us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 8/8\n",
      "6499/6499 [==============================] - 1s 194us/step - loss: 0.0020 - acc: 0.9995\n",
      "6499/6499 [==============================] - 0s 52us/step\n",
      "acc: 99.95%\n",
      "[[843   0]\n",
      " [  1 781]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "\n",
    "\n",
    "dataset.head(10)\n",
    "dataset.describe()\n",
    "dataset.info()\n",
    "#dataset.loc[dataset[\"EDIBLE\"].isnull()]\n",
    "\n",
    "#assign X and y\n",
    "X = dataset.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]].values\n",
    "y = dataset.iloc[:, [0]].values\n",
    "#X = pd.DataFrame(X)\n",
    "#y = pd.DataFrame(y)\n",
    "\n",
    "\n",
    "# Encoding categorical data for X dummy variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "labelencoder_X_0 = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X_2.fit_transform(X[:, 0])\n",
    "labelencoder_X_3 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X_2.fit_transform(X[:, 3])\n",
    "labelencoder_X_4 = LabelEncoder()\n",
    "X[:, 4] = labelencoder_X_2.fit_transform(X[:, 4])\n",
    "labelencoder_X_5 = LabelEncoder()\n",
    "X[:, 5] = labelencoder_X_2.fit_transform(X[:, 5])\n",
    "labelencoder_X_6 = LabelEncoder()\n",
    "X[:, 6] = labelencoder_X_2.fit_transform(X[:, 6])\n",
    "labelencoder_X_7 = LabelEncoder()\n",
    "X[:, 7] = labelencoder_X_2.fit_transform(X[:, 7])\n",
    "labelencoder_X_8 = LabelEncoder()\n",
    "X[:, 8] = labelencoder_X_2.fit_transform(X[:, 8])\n",
    "labelencoder_X_9 = LabelEncoder()\n",
    "X[:, 9] = labelencoder_X_2.fit_transform(X[:, 9])\n",
    "labelencoder_X_10 = LabelEncoder()\n",
    "X[:, 10] = labelencoder_X_2.fit_transform(X[:, 10])\n",
    "labelencoder_X_11 = LabelEncoder()\n",
    "X[:, 11] = labelencoder_X_2.fit_transform(X[:, 11])\n",
    "labelencoder_X_12 = LabelEncoder()\n",
    "X[:, 12] = labelencoder_X_2.fit_transform(X[:, 12])\n",
    "labelencoder_X_13 = LabelEncoder()\n",
    "X[:, 13] = labelencoder_X_2.fit_transform(X[:, 13])\n",
    "labelencoder_X_14 = LabelEncoder()\n",
    "X[:, 14] = labelencoder_X_2.fit_transform(X[:, 14])\n",
    "labelencoder_X_15 = LabelEncoder()\n",
    "X[:, 15] = labelencoder_X_2.fit_transform(X[:, 15])\n",
    "labelencoder_X_16 = LabelEncoder()\n",
    "X[:, 16] = labelencoder_X_2.fit_transform(X[:, 16])\n",
    "labelencoder_X_17 = LabelEncoder()\n",
    "X[:, 17] = labelencoder_X_2.fit_transform(X[:, 17])\n",
    "labelencoder_X_18 = LabelEncoder()\n",
    "X[:, 18] = labelencoder_X_2.fit_transform(X[:, 18])\n",
    "labelencoder_X_19 = LabelEncoder()\n",
    "X[:, 19] = labelencoder_X_2.fit_transform(X[:, 19])\n",
    "labelencoder_X_20 = LabelEncoder()\n",
    "X[:, 20] = labelencoder_X_2.fit_transform(X[:, 20])\n",
    "labelencoder_X_21 = LabelEncoder()\n",
    "X[:, 21] = labelencoder_X_2.fit_transform(X[:, 21])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "\n",
    "#encoding for y\n",
    "labelencoder_y_0 = LabelEncoder()\n",
    "y[:, 0] = labelencoder_y_0.fit_transform(y[:, 0])\n",
    "\n",
    "#split data -try the model with random state 42 and also it is checked with random state 0\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu', input_dim = 24))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu'))\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 8)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = y_pred.round().astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "scores = classifier.evaluate(X_train, y_train) \n",
    "print(\"%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "print(cm)"
  
